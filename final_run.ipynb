{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navin1111/CAPSTONE_PROJECT/blob/main/final_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4Fk21SuxeE",
        "outputId": "9464af04-fd58-4882-ebf3-73c48f0d75cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.5.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: litellm in /usr/local/lib/python3.10/dist-packages (1.52.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.4)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.4.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.2)\n",
            "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.2)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.15)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.137)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (8.5.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (1.54.3)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (1.0.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm) (0.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.20.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.0->litellm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.0->litellm) (0.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio langchain-community litellm PyPDF2 torch pypdf faiss-cpu pdf2image pytesseract transformers\n",
        "!apt-get install -q -y poppler-utils tesseract-ocr libtesseract-dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] = getpass(\"Enter your GEMINI API Key:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEhEXr8AY3Qr",
        "outputId": "220a6475-3da0-492c-ff33-b5712f12ecd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GEMINI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.environ['GEMINI_API_KEY']\n"
      ],
      "metadata": {
        "id": "UewqZxlxZNAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZfLnkfuzGM",
        "outputId": "184beacc-e0a0-4c3c-92b2-4906fc5743f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pytesseract\n",
        "import gradio as gr\n",
        "import os\n",
        "import tempfile\n",
        "from pdf2image import convert_from_path\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import numpy as np\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import concurrent.futures\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "from google.colab import files\n",
        "import base64\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Set Tesseract path for Colab\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "\n",
        "# Load the models globally\n",
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "class CharacterTextSplitterWithPageNumbers(CharacterTextSplitter):\n",
        "    def __init__(self, chunk_size=1000, chunk_overlap=200, **kwargs):\n",
        "        super().__init__(chunk_size=chunk_size, chunk_overlap=chunk_overlap, **kwargs)\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "\n",
        "    def split_documents(self, documents):\n",
        "        chunks = []\n",
        "        for doc in documents:\n",
        "            page_num = doc['page_number']\n",
        "            content = doc['content']\n",
        "\n",
        "            while len(content) > 0:\n",
        "                chunk = content[:self.chunk_size]\n",
        "                chunks.append({'content': chunk, 'page_number': page_num})\n",
        "                content = content[self.chunk_size - self.chunk_overlap:]\n",
        "\n",
        "        return chunks\n",
        "\n",
        "class PDFChatbot:\n",
        "    def __init__(self):\n",
        "        self.index = None\n",
        "        self.texts = None\n",
        "        self.current_pdf_path = None\n",
        "\n",
        "    def extract_text_from_image(self, image, page_num):\n",
        "        text = pytesseract.image_to_string(image)\n",
        "        return {'content': text, 'page_number': page_num + 1}\n",
        "\n",
        "    def get_text_from_file_tesseract(self, file_path):\n",
        "        images = convert_from_path(file_path)\n",
        "\n",
        "        texts = []\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(self.extract_text_from_image, img, idx)\n",
        "                      for idx, img in enumerate(images)]\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                texts.append(future.result())\n",
        "\n",
        "        return sorted(texts, key=lambda x: x['page_number'])\n",
        "\n",
        "    def get_embeddings(self, texts):\n",
        "        embeddings = []\n",
        "        for text in texts:\n",
        "            inputs = tokenizer(text['content'], return_tensors='pt', truncation=True,\n",
        "                             padding=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            embeddings.append({'embedding': embedding, 'page_number': text['page_number']})\n",
        "        return embeddings\n",
        "\n",
        "    def process_pdf(self, file_obj):\n",
        "        # Save uploaded file to temporary location\n",
        "        temp_dir = tempfile.mkdtemp()\n",
        "        temp_path = os.path.join(temp_dir, \"uploaded.pdf\")\n",
        "\n",
        "        # Handle both file object from Gradio and direct file path\n",
        "        if isinstance(file_obj, str):\n",
        "            temp_path = file_obj\n",
        "        else:\n",
        "            with open(temp_path, 'wb') as f:\n",
        "                f.write(file_obj.read())\n",
        "\n",
        "        # Extract text from PDF\n",
        "        try:\n",
        "            documents = self.get_text_from_file_tesseract(temp_path)\n",
        "\n",
        "            # Split text into chunks\n",
        "            text_splitter = CharacterTextSplitterWithPageNumbers(chunk_size=1000, chunk_overlap=200)\n",
        "            self.texts = text_splitter.split_documents(documents)\n",
        "\n",
        "            # Generate embeddings\n",
        "            embeddings = self.get_embeddings(self.texts)\n",
        "            embedding_vectors = np.array([emb['embedding'] for emb in embeddings], dtype=np.float32)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = embedding_vectors.shape[1]\n",
        "            self.index = faiss.IndexFlatL2(dimension)\n",
        "            self.index.add(embedding_vectors)\n",
        "\n",
        "            return \"PDF processed successfully! You can now ask questions about the document.\"\n",
        "        except Exception as e:\n",
        "            return f\"Error processing PDF: {str(e)}\"\n",
        "\n",
        "    def find_most_similar_document(self, query):\n",
        "        inputs = tokenizer(query, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        query_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "        D, I = self.index.search(np.array([query_embedding], dtype=np.float32), k=1)\n",
        "        most_similar_idx = I[0][0]\n",
        "        return self.texts[most_similar_idx]['content'], self.texts[most_similar_idx]['page_number']\n",
        "\n",
        "    def get_response(self, query):\n",
        "        \"\"\"Generates a response using the Gemini Pro model.\"\"\"\n",
        "        response = completion(\n",
        "            model=\"gemini/gemini-pro\",\n",
        "            messages=[{\"role\": \"user\", \"content\": query}]\n",
        "        )\n",
        "        return response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
        "\n",
        "    def get_answer_from_pdf(self, query):\n",
        "        if self.index is None:\n",
        "            return \"Please upload a PDF first!\", 0\n",
        "\n",
        "        most_similar_document_content, page_number = self.find_most_similar_document(query)\n",
        "        prompt = f\"Based on the following content:\\n\\n{most_similar_document_content}\\n\\nAnswer the following question: {query}\"\n",
        "        answer = self.get_response(prompt)\n",
        "        return answer, page_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwvUnNyLwoXL"
      },
      "outputs": [],
      "source": [
        "def create_ui():\n",
        "    chatbot = PDFChatbot()\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"# PDF Question Answering System\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                file_output = gr.File(label=\"Upload PDF\")\n",
        "                status_output = gr.Textbox(label=\"Status\", placeholder=\"Upload a PDF to begin...\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                chatbot_ui = gr.Chatbot(label=\"Chat History\")\n",
        "                msg = gr.Textbox(label=\"Ask a question about the PDF\", placeholder=\"Type your question here...\")\n",
        "                clear = gr.Button(\"Clear\")\n",
        "\n",
        "        def user_query(message, history):\n",
        "            if chatbot.index is None:\n",
        "                response = \"Please upload a PDF first!\"\n",
        "                history.append((message, response))\n",
        "                return \"\", history\n",
        "\n",
        "            answer, page_number = chatbot.get_answer_from_pdf(message)\n",
        "            response = f\"{answer}\\n\\nFound on Page: {page_number}\"\n",
        "            history.append((message, response))\n",
        "            return \"\", history\n",
        "\n",
        "        def process_pdf(file):\n",
        "            if file is None:\n",
        "                return \"Please upload a PDF file.\"\n",
        "            try:\n",
        "                result = chatbot.process_pdf(file)\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                return f\"Error processing PDF: {str(e)}\"\n",
        "\n",
        "        msg.submit(user_query, [msg, chatbot_ui], [msg, chatbot_ui])\n",
        "        file_output.upload(process_pdf, file_output, status_output)\n",
        "        clear.click(lambda: None, None, chatbot_ui, queue=False)\n",
        "\n",
        "    return demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ug5mfWVvhIu"
      },
      "outputs": [],
      "source": [
        "# Create a cell to set your API key\n",
        "#os.environ['GEMINI_API_KEY'] = \"AIzaSyBQ0_JY2d68Dn6Qr82uRnnN-pQNFlDFTzY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "E7hljjUdv0Ph",
        "outputId": "7116875a-66f5-41df-e492-c6d1528ad682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c731e48e6112a6b88c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c731e48e6112a6b88c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://c731e48e6112a6b88c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Create a cell to launch the interface\n",
        "demo = create_ui()\n",
        "demo.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLvYHreBa0Lf",
        "outputId": "b9d88bcd-d748-4c18-8201-471f6b04c012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm9puMpbv3r0"
      },
      "outputs": [],
      "source": [
        "!git remote remove origin\n",
        "!git remote add origin https://github.com/navin1111/CAPSTONE_PROJECT.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n"
      ],
      "metadata": {
        "id": "cluj-XwUabGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Initial commit with PDF processing and chatbot code\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2INj__fa9RV",
        "outputId": "52ae672c-d88d-4334-8d82-741daf09da51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@27739749087e.(none)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push -u origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBAPUfbkbs7b",
        "outputId": "1b856f30-1744-42be-e884-4c7e90c910b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: src refspec main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/navin1111/CAPSTONE_PROJECT.git'\n",
            "\u001b[m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZi-q3y_bvqi",
        "outputId": "e821d31b-0512-4486-c18a-039e8c0fb91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "\n",
            "No commits yet\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git rm --cached <file>...\" to unstage)\n",
            "\t\u001b[32mnew file:   .config/.last_opt_in_prompt.yaml\u001b[m\n",
            "\t\u001b[32mnew file:   .config/.last_survey_prompt.yaml\u001b[m\n",
            "\t\u001b[32mnew file:   .config/.last_update_check.json\u001b[m\n",
            "\t\u001b[32mnew file:   .config/active_config\u001b[m\n",
            "\t\u001b[32mnew file:   .config/config_sentinel\u001b[m\n",
            "\t\u001b[32mnew file:   .config/configurations/config_default\u001b[m\n",
            "\t\u001b[32mnew file:   .config/default_configs.db\u001b[m\n",
            "\t\u001b[32mnew file:   .config/gce\u001b[m\n",
            "\t\u001b[32mnew file:   .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\u001b[m\n",
            "\t\u001b[32mnew file:   .config/logs/2024.11.06/14.22.28.082325.log\u001b[m\n",
            "\t\u001b[32mnew file:   .config/logs/2024.11.06/14.22.49.463793.log\u001b[m\n",
            "\t\u001b[32mnew file:   .config/logs/2024.11.06/14.23.01.961464.log\u001b[m\n",
            "\t\u001b[32mnew file:   .config/logs/2024.11.06/14.23.02.977294.log\u001b[m\n",
            "\t\u001b[32mnew file:   .config/logs/2024.11.06/14.23.15.846674.log\u001b[m\n",
            "\t\u001b[32mnew file:   .config/logs/2024.11.06/14.23.16.565928.log\u001b[m\n",
            "\t\u001b[32mnew file:   .gradio/certificate.pem\u001b[m\n",
            "\t\u001b[32mnew file:   sample_data/README.md\u001b[m\n",
            "\t\u001b[32mnew file:   sample_data/anscombe.json\u001b[m\n",
            "\t\u001b[32mnew file:   sample_data/california_housing_test.csv\u001b[m\n",
            "\t\u001b[32mnew file:   sample_data/california_housing_train.csv\u001b[m\n",
            "\t\u001b[32mnew file:   sample_data/mnist_test.csv\u001b[m\n",
            "\t\u001b[32mnew file:   sample_data/mnist_train_small.csv\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75o-ZS5KcDQb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6PLPT6ZagpKvV7L+jmnAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}